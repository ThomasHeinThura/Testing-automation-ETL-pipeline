{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* you need to make model pipline and testing the model with it (error)\n",
    "\n",
    "* Saving confusion matrix in MLFLOW (Good)\n",
    " \n",
    "* Need to add sqlite backend and automatic regristary the model (Good)\n",
    "  \n",
    "* add experiment name and add vresion (version is git version)\n",
    "\n",
    "* add automatic select the best model and predict the model with it with new unseen dataset. (automatic select the best model by f1 is done and predict with selection model is done)\n",
    "  \n",
    "* Train test val spliiting in dataset (we wil try in another dataset)\n",
    "  \n",
    "* Make result dataframe and output file ( we wil ltry in another dataset)\n",
    "\n",
    "* MOve all parameters to main file and remove from others\n",
    "\n",
    "* make argv to make sure what model need to be train.  (arg.prease try is done)\n",
    "\n",
    "* print to logger (we will try in another dataset)\n",
    "  \n",
    "* Make new dataset for testing deploy model\n",
    "\n",
    "* Deployment to flask and docker\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://127.0.0.1:5000'\n"
     ]
    }
   ],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1682395858287, experiment_id='1', last_update_time=1682395858287, lifecycle_stage='active', name='my-experiment-1', tags={}>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"my-experiment-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1682395858287, experiment_id='1', last_update_time=1682395858287, lifecycle_stage='active', name='my-experiment-1', tags={}>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score,confusion_matrix,classification_report\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "# others\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "import argparse\n",
    "from urllib.parse import urlparse\n",
    "import logging\n",
    "import warnings\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "\n",
    "# from params_loader import read_params\n",
    "# from models import build_and_load_models\n",
    "# from check_data_exist import check_dataset_exist\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# np.random.seed(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SKlearn model\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import  RadiusNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "# from catboost import Pool, CatBoostClassifier, cv\n",
    "# import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "def build_and_load_models():\n",
    "    # Models\n",
    "    Models = {\n",
    "        \"Logistic Regression\": LogisticRegression(),                    #\n",
    "        \"Support Vector Classifier\": SVC(),                             # Ridge, SVC, LinearSVC, Passive_AC\n",
    "        \"Decision Tree\": DecisionTreeClassifier(max_depth=6),           #\n",
    "        \"KNearest\": KNeighborsClassifier(n_neighbors=5),                # doesn't have model.predict_proba so I left out.\n",
    "        \"GaussianNB\" : GaussianNB(),                                    #\n",
    "        \"LDA\" : LinearDiscriminantAnalysis(),                           # \n",
    "        \"Ridge\" : RidgeClassifier(),                                    #  \n",
    "        \"QDA\" : QuadraticDiscriminantAnalysis(),                        #\n",
    "        \"Bagging\" : BaggingClassifier(),                                #\n",
    "        \"MLP\" : MLPClassifier(),                                        #\n",
    "        \"LSVC\" : LinearSVC(),                                           #  \n",
    "        \"BernoulliNB\" : BernoulliNB(),                                  #  \n",
    "        \"Passive_AC\" : PassiveAggressiveClassifier(),                   # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #  \n",
    "        \"SGB\"     : GradientBoostingClassifier(n_estimators=100, random_state=9),\n",
    "        \"Adaboost\" : AdaBoostClassifier(n_estimators=100, random_state=9, algorithm='SAMME.R', learning_rate=0.8),\n",
    "        \"Extra_T\" : ExtraTreesClassifier(n_estimators=100, max_features=3),\n",
    "        \"R_forest\" : RandomForestClassifier(max_samples=0.9, n_estimators=100, max_features=3),\n",
    "        # \"XGB\" : xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)\n",
    "        }\n",
    "    return Models\n",
    " \n",
    "\n",
    "### Add lgb, catboost and Stacking and ANN\n",
    "\n",
    "\n",
    "### virtualize end result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '../data/processed/undersampling_train.parquet'\n",
    "test_data_path  = '../data/processed/undersampling_test.parquet'\n",
    "target = 'Class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../src/data/\")\n",
    "from data_function import get_feat_and_target\n",
    "def features_labels_split(train_data_path, test_data_path, target):\n",
    "    train_dataset = pd.read_parquet(train_data_path)\n",
    "    test_dataset = pd.read_parquet(test_data_path)\n",
    "    train_features,train_label = get_feat_and_target(train_dataset, target)\n",
    "    test_features,test_label = get_feat_and_target(test_dataset, target)\n",
    "    return train_features, train_label, test_features, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliiting X and y\n",
      "spliiting X and y\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_parquet(train_data_path)\n",
    "test_dataset = pd.read_parquet(test_data_path)\n",
    "train_features,train_label = get_feat_and_target(train_dataset, target)\n",
    "test_features,test_label = get_feat_and_target(test_dataset, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    " Models = build_and_load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': LogisticRegression(),\n",
       " 'Support Vector Classifier': SVC(),\n",
       " 'Decision Tree': DecisionTreeClassifier(max_depth=6),\n",
       " 'KNearest': KNeighborsClassifier(),\n",
       " 'GaussianNB': GaussianNB(),\n",
       " 'LDA': LinearDiscriminantAnalysis(),\n",
       " 'Ridge': RidgeClassifier(),\n",
       " 'QDA': QuadraticDiscriminantAnalysis(),\n",
       " 'Bagging': BaggingClassifier(),\n",
       " 'MLP': MLPClassifier(),\n",
       " 'LSVC': LinearSVC(),\n",
       " 'BernoulliNB': BernoulliNB(),\n",
       " 'Passive_AC': PassiveAggressiveClassifier(),\n",
       " 'SGB': GradientBoostingClassifier(random_state=9),\n",
       " 'Adaboost': AdaBoostClassifier(learning_rate=0.8, n_estimators=100, random_state=9),\n",
       " 'Extra_T': ExtraTreesClassifier(max_features=3),\n",
       " 'R_forest': RandomForestClassifier(max_features=3, max_samples=0.9)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(classifier, test_features, test_labels, avg_method):\n",
    "    \n",
    "    # make prediction\n",
    "    predictions   = classifier.predict(test_features)\n",
    "    base_score   = classifier.score(test_features,test_labels)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions, average=avg_method)\n",
    "    recall = recall_score(test_labels, predictions, average=avg_method)\n",
    "    f1score = f1_score(test_labels, predictions, average=avg_method)\n",
    "    Matrix = confusion_matrix(test_labels, predictions)\n",
    "    matrix_scores = { \n",
    "        \"true negative\"  : Matrix[0][0],\n",
    "        \"false positive\" : Matrix[0][1],\n",
    "        \"false negative\" : Matrix[1][0],\n",
    "        \"true positive \" : Matrix[1][1]\n",
    "    }\n",
    "    target_names = ['0','1']\n",
    "    print(\"Classification report\")\n",
    "    print(\"---------------------\",\"\\n\")\n",
    "    print(classification_report(test_labels, predictions,target_names=target_names),\"\\n\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(\"---------------------\",\"\\n\")\n",
    "    print(f\"{Matrix} \\n\")\n",
    "\n",
    "    print(\"Accuracy Measures\")\n",
    "    print(\"---------------------\",\"\\n\")\n",
    "    print(\"Base score: \", base_score)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 Score: \", f1score)\n",
    "    \n",
    "    return base_score,accuracy,precision,recall,f1score,matrix_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Logistic Regression\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93        98\n",
      "           1       0.98      0.87      0.92        99\n",
      "\n",
      "    accuracy                           0.92       197\n",
      "   macro avg       0.93      0.92      0.92       197\n",
      "weighted avg       0.93      0.92      0.92       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[96  2]\n",
      " [13 86]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.9238578680203046\n",
      "Accuracy:  0.9238578680203046\n",
      "Precision:  0.9292483584035767\n",
      "Recall:  0.9238578680203046\n",
      "F1 Score:  0.923641493675378\n",
      "________________________________________\n",
      "2. Support Vector Classifier\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92        98\n",
      "           1       0.99      0.84      0.91        99\n",
      "\n",
      "    accuracy                           0.91       197\n",
      "   macro avg       0.92      0.91      0.91       197\n",
      "weighted avg       0.92      0.91      0.91       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[97  1]\n",
      " [16 83]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.9137055837563451\n",
      "Accuracy:  0.9137055837563451\n",
      "Precision:  0.9235803166331894\n",
      "Recall:  0.9137055837563451\n",
      "F1 Score:  0.9132362644231888\n",
      "________________________________________\n",
      "3. Decision Tree\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        98\n",
      "           1       0.93      0.93      0.93        99\n",
      "\n",
      "    accuracy                           0.93       197\n",
      "   macro avg       0.93      0.93      0.93       197\n",
      "weighted avg       0.93      0.93      0.93       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[91  7]\n",
      " [ 7 92]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.9289340101522843\n",
      "Accuracy:  0.9289340101522843\n",
      "Precision:  0.9289340101522843\n",
      "Recall:  0.9289340101522843\n",
      "F1 Score:  0.9289340101522843\n",
      "________________________________________\n",
      "4. KNearest\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93        98\n",
      "           1       0.99      0.86      0.92        99\n",
      "\n",
      "    accuracy                           0.92       197\n",
      "   macro avg       0.93      0.92      0.92       197\n",
      "weighted avg       0.93      0.92      0.92       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[97  1]\n",
      " [14 85]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.9238578680203046\n",
      "Accuracy:  0.9238578680203046\n",
      "Precision:  0.9314135880656952\n",
      "Recall:  0.9238578680203046\n",
      "F1 Score:  0.9235506606599313\n",
      "________________________________________\n",
      "5. GaussianNB\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92        98\n",
      "           1       0.99      0.85      0.91        99\n",
      "\n",
      "    accuracy                           0.92       197\n",
      "   macro avg       0.93      0.92      0.92       197\n",
      "weighted avg       0.93      0.92      0.92       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[97  1]\n",
      " [15 84]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.9187817258883249\n",
      "Accuracy:  0.9187817258883249\n",
      "Precision:  0.9274634219169902\n",
      "Recall:  0.9187817258883249\n",
      "F1 Score:  0.9183991760464946\n",
      "________________________________________\n",
      "6. LDA\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90        98\n",
      "           1       0.94      0.85      0.89        99\n",
      "\n",
      "    accuracy                           0.90       197\n",
      "   macro avg       0.90      0.90      0.90       197\n",
      "weighted avg       0.90      0.90      0.90       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[93  5]\n",
      " [15 84]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.8984771573604061\n",
      "Accuracy:  0.8984771573604061\n",
      "Precision:  0.9026755895232482\n",
      "Recall:  0.8984771573604061\n",
      "F1 Score:  0.8982412284242989\n",
      "________________________________________\n",
      "7. Ridge\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90        98\n",
      "           1       0.94      0.85      0.89        99\n",
      "\n",
      "    accuracy                           0.90       197\n",
      "   macro avg       0.90      0.90      0.90       197\n",
      "weighted avg       0.90      0.90      0.90       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[93  5]\n",
      " [15 84]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.8984771573604061\n",
      "Accuracy:  0.8984771573604061\n",
      "Precision:  0.9026755895232482\n",
      "Recall:  0.8984771573604061\n",
      "F1 Score:  0.8982412284242989\n",
      "________________________________________\n",
      "8. QDA\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        98\n",
      "           1       0.94      0.94      0.94        99\n",
      "\n",
      "    accuracy                           0.94       197\n",
      "   macro avg       0.94      0.94      0.94       197\n",
      "weighted avg       0.94      0.94      0.94       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[92  6]\n",
      " [ 6 93]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.9390862944162437\n",
      "Accuracy:  0.9390862944162437\n",
      "Precision:  0.9390862944162437\n",
      "Recall:  0.9390862944162437\n",
      "F1 Score:  0.9390862944162437\n",
      "________________________________________\n",
      "9. Bagging\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95        98\n",
      "           1       0.97      0.94      0.95        99\n",
      "\n",
      "    accuracy                           0.95       197\n",
      "   macro avg       0.95      0.95      0.95       197\n",
      "weighted avg       0.95      0.95      0.95       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[95  3]\n",
      " [ 6 93]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.9543147208121827\n",
      "Accuracy:  0.9543147208121827\n",
      "Precision:  0.9547434914811278\n",
      "Recall:  0.9543147208121827\n",
      "F1 Score:  0.9543076569885742\n",
      "________________________________________\n",
      "10. MLP\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        98\n",
      "           1       0.98      0.92      0.95        99\n",
      "\n",
      "    accuracy                           0.95       197\n",
      "   macro avg       0.95      0.95      0.95       197\n",
      "weighted avg       0.95      0.95      0.95       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[96  2]\n",
      " [ 8 91]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.949238578680203\n",
      "Accuracy:  0.949238578680203\n",
      "Precision:  0.9509264274288017\n",
      "Recall:  0.949238578680203\n",
      "F1 Score:  0.9491993139669298\n",
      "________________________________________\n",
      "11. LSVC\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        98\n",
      "           1       0.98      0.88      0.93        99\n",
      "\n",
      "    accuracy                           0.93       197\n",
      "   macro avg       0.93      0.93      0.93       197\n",
      "weighted avg       0.93      0.93      0.93       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[96  2]\n",
      " [12 87]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.9289340101522843\n",
      "Accuracy:  0.9289340101522843\n",
      "Precision:  0.933433461979632\n",
      "Recall:  0.9289340101522843\n",
      "F1 Score:  0.9287688598970091\n",
      "________________________________________\n",
      "12. BernoulliNB\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90        98\n",
      "           1       0.98      0.80      0.88        99\n",
      "\n",
      "    accuracy                           0.89       197\n",
      "   macro avg       0.90      0.89      0.89       197\n",
      "weighted avg       0.90      0.89      0.89       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[96  2]\n",
      " [20 79]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.8883248730964467\n",
      "Accuracy:  0.8883248730964467\n",
      "Precision:  0.9018223544742012\n",
      "Recall:  0.8883248730964467\n",
      "F1 Score:  0.8874377342378671\n",
      "________________________________________\n",
      "13. Passive_AC\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        98\n",
      "           1       0.98      0.88      0.93        99\n",
      "\n",
      "    accuracy                           0.93       197\n",
      "   macro avg       0.93      0.93      0.93       197\n",
      "weighted avg       0.93      0.93      0.93       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[96  2]\n",
      " [12 87]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.9289340101522843\n",
      "Accuracy:  0.9289340101522843\n",
      "Precision:  0.933433461979632\n",
      "Recall:  0.9289340101522843\n",
      "F1 Score:  0.9287688598970091\n",
      "________________________________________\n",
      "14. SGB\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        98\n",
      "           1       0.97      0.95      0.96        99\n",
      "\n",
      "    accuracy                           0.96       197\n",
      "   macro avg       0.96      0.96      0.96       197\n",
      "weighted avg       0.96      0.96      0.96       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[95  3]\n",
      " [ 5 94]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.9593908629441624\n",
      "Accuracy:  0.9593908629441624\n",
      "Precision:  0.9595844889842483\n",
      "Recall:  0.9593908629441624\n",
      "F1 Score:  0.959388770121185\n",
      "________________________________________\n",
      "15. Adaboost\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95        98\n",
      "           1       0.95      0.96      0.95        99\n",
      "\n",
      "    accuracy                           0.95       197\n",
      "   macro avg       0.95      0.95      0.95       197\n",
      "weighted avg       0.95      0.95      0.95       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[93  5]\n",
      " [ 4 95]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.9543147208121827\n",
      "Accuracy:  0.9543147208121827\n",
      "Precision:  0.9543592024700402\n",
      "Recall:  0.9543147208121827\n",
      "F1 Score:  0.9543123662043134\n",
      "________________________________________\n",
      "16. Extra_T\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        98\n",
      "           1       0.99      0.93      0.96        99\n",
      "\n",
      "    accuracy                           0.96       197\n",
      "   macro avg       0.96      0.96      0.96       197\n",
      "weighted avg       0.96      0.96      0.96       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[97  1]\n",
      " [ 7 92]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.9593908629441624\n",
      "Accuracy:  0.9593908629441624\n",
      "Precision:  0.961113350379766\n",
      "Recall:  0.9593908629441624\n",
      "F1 Score:  0.9593594511735436\n",
      "________________________________________\n",
      "17. R_forest\n",
      "Classification report\n",
      "--------------------- \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96        98\n",
      "           1       0.98      0.93      0.95        99\n",
      "\n",
      "    accuracy                           0.95       197\n",
      "   macro avg       0.96      0.95      0.95       197\n",
      "weighted avg       0.96      0.95      0.95       197\n",
      " \n",
      "\n",
      "Confusion Matrix\n",
      "--------------------- \n",
      "\n",
      "[[96  2]\n",
      " [ 7 92]] \n",
      "\n",
      "Accuracy Measures\n",
      "--------------------- \n",
      "\n",
      "Base score:  0.9543147208121827\n",
      "Accuracy:  0.9543147208121827\n",
      "Precision:  0.9554996083579661\n",
      "Recall:  0.9543147208121827\n",
      "F1 Score:  0.9542911674498813\n",
      "________________________________________\n"
     ]
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "i = 1\n",
    "for Model_Name, classifier in Models.items():   \n",
    "        with mlflow.start_run():\n",
    "                print(f\"{i}. {Model_Name}\")\n",
    "                # fit the model\n",
    "                classifier.fit(train_features, train_label)\n",
    "                i = i+1\n",
    "                # Calculate the metrics\n",
    "                base_score,accuracy,precision,recall,f1score,matrix_scores = eval_metrics(classifier, \n",
    "                                                                        test_features, \n",
    "                                                                        test_label, \n",
    "                                                                        'weighted')\n",
    "                \n",
    "                mlflow.log_param(\"Models\"            , Model_Name)\n",
    "                mlflow.log_params(matrix_scores)\n",
    "                mlflow.log_metric(\"base_score\"      , base_score)\n",
    "                mlflow.log_metric(\"accuary\"         , accuracy)\n",
    "                mlflow.log_metric(\"av_precision\"    , precision)\n",
    "                mlflow.log_metric(\"recall\"          , recall)\n",
    "                mlflow.log_metric(\"f1\"              , f1score)\n",
    "                signature = infer_signature(test_features, classifier.predict(test_features))\n",
    "                if f1score > 0.945 :\n",
    "                        mlflow.sklearn.log_model(classifier,Model_Name, signature=signature)\n",
    "                print(\"________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with mlflow.start_run():\n",
    "#     lr = LogisticRegression()\n",
    "#     lr.fit(train_features, train_label)\n",
    "#     signature = infer_signature(test_features, lr.predict(test_features))\n",
    "#     base_score,accuracy,precision,recall,f1score,matrix_scores = eval_metrics(lr, \n",
    "#                                                             test_features, \n",
    "#                                                             test_label, \n",
    "#                                                             'weighted')\n",
    "\n",
    "#     mlflow.log_param(\"Models\"            , lr)\n",
    "#     mlflow.log_params(matrix_scores)\n",
    "#     mlflow.log_metric(\"base_score\"      , base_score)\n",
    "#     mlflow.log_metric(\"accuary\"         , accuracy)\n",
    "#     mlflow.log_metric(\"av_precision\"    , precision)\n",
    "#     mlflow.log_metric(\"recall\"          , recall)\n",
    "#     mlflow.log_metric(\"f1\"              , f1score)\n",
    "#     mlflow.sklearn.log_model(lr, \"logistic regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mlflow.search_runs(filter_string=\"metrics.f1 > 0.945\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    171028b9a18646ecaa20f0bec240a548\n",
       "1    136a9367ee8645c6b982e656e06b0019\n",
       "2    08bb22c78ea64a1bbadc198ca09cc03f\n",
       "3    ff6268ca0af04f91b7af19e8436939e8\n",
       "4    582c295b97d744e79262e2e855910a8b\n",
       "5    d8e6bc5b56474696a25fd1d1279cbdb6\n",
       "Name: run_id, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['run_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    R_forest\n",
       "1     Extra_T\n",
       "2    Adaboost\n",
       "3         SGB\n",
       "4         MLP\n",
       "5     Bagging\n",
       "Name: params.Models, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['params.Models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extra_T'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = [df['run_id'][1], df['params.Models'][1]]\n",
    "run_id[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_id = '1baadc44789547928598b3214477b955'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "logged_model = f'runs:/{run_id[0]}/{run_id[1]}'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "predict = loaded_model.predict(test_features)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Run_id is :171028b9a18646ecaa20f0bec240a548\n",
      "R_forest prediciton is \n",
      " [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1\n",
      " 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
      " 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 0\n",
      " 1 1 0 0 1 0 0 0 1 0 0 1]\n",
      "1\n",
      "Run_id is :136a9367ee8645c6b982e656e06b0019\n",
      "Extra_T prediciton is \n",
      " [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 1\n",
      " 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
      " 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 0\n",
      " 1 1 0 0 1 0 0 0 1 0 0 1]\n",
      "2\n",
      "Run_id is :08bb22c78ea64a1bbadc198ca09cc03f\n",
      "Adaboost prediciton is \n",
      " [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1\n",
      " 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
      " 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0\n",
      " 1 1 0 1 1 0 0 0 1 0 0 1]\n",
      "3\n",
      "Run_id is :ff6268ca0af04f91b7af19e8436939e8\n",
      "SGB prediciton is \n",
      " [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1\n",
      " 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
      " 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 0\n",
      " 1 1 0 0 1 0 0 0 1 0 0 1]\n",
      "4\n",
      "Run_id is :582c295b97d744e79262e2e855910a8b\n",
      "MLP prediciton is \n",
      " [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 1 0 1\n",
      " 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
      " 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 1 0 1 0 1 1 0 1 0 0\n",
      " 1 1 0 0 1 0 0 0 1 0 0 1]\n",
      "5\n",
      "Run_id is :d8e6bc5b56474696a25fd1d1279cbdb6\n",
      "Bagging prediciton is \n",
      " [1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1\n",
      " 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0\n",
      " 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 1\n",
      " 0 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 0\n",
      " 1 1 0 0 1 0 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    print(i)\n",
    "    run_id = df['run_id'][i]\n",
    "    print(f'Run_id is :{run_id}')\n",
    "    model = df['params.Models'][i]\n",
    "    logged_model = f'runs:/{run_id}/{model}'\n",
    "\n",
    "    # Load model as a PyFuncModel.\n",
    "    loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "    # Predict on a Pandas DataFrame.\n",
    "    import pandas as pd\n",
    "    predict = loaded_model.predict(test_features)\n",
    "    print(f'{model} prediciton is \\n {predict}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
