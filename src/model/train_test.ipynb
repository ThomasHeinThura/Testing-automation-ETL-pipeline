{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* you need to make model pipline and testing the model with it (error)\n",
    "\n",
    "* Saving confusion matrix in MLFLOW (Good)\n",
    " \n",
    "* Need to add sqlite backend and automatic regristary the model\n",
    "  \n",
    "* add experiment name and add vresion\n",
    "\n",
    "* add automatic select the best model and predict the model with it with new unseen dataset.\n",
    "  \n",
    "* Train test val spliiting in dataset\n",
    "  \n",
    "* Make result dataframe and output file\n",
    "\n",
    "* MOve all parameters to main file and remove from others\n",
    "\n",
    "* make argv to make sure what model need to be train. \n",
    "\n",
    "* print to logger\n",
    "  \n",
    "* Make new dataset for testing deploy model\n",
    "\n",
    "* Deployment to flask and docker\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://127.0.0.1:5000'\n"
     ]
    }
   ],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1682395858287, experiment_id='1', last_update_time=1682395858287, lifecycle_stage='active', name='my-experiment-1', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"my-experiment-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1682395858287, experiment_id='1', last_update_time=1682395858287, lifecycle_stage='active', name='my-experiment-1', tags={}>,\n",
       " <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1682395714480, experiment_id='0', last_update_time=1682395714480, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1682395858287, experiment_id='1', last_update_time=1682395858287, lifecycle_stage='active', name='my-experiment-1', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.get_experiment(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score,confusion_matrix,classification_report\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "# others\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "import argparse\n",
    "from urllib.parse import urlparse\n",
    "import logging\n",
    "import warnings\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "\n",
    "# from params_loader import read_params\n",
    "# from models import build_and_load_models\n",
    "# from check_data_exist import check_dataset_exist\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# np.random.seed(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SKlearn model\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import  RadiusNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "# from catboost import Pool, CatBoostClassifier, cv\n",
    "# import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "def build_and_load_models():\n",
    "    # Models\n",
    "    Models = {\n",
    "        \"Logistic Regression\": LogisticRegression(),                    #\n",
    "        \"Support Vector Classifier\": SVC(),                             # Ridge, SVC, LinearSVC, Passive_AC\n",
    "        \"Decision Tree\": DecisionTreeClassifier(max_depth=6),           #\n",
    "        \"KNearest\": KNeighborsClassifier(n_neighbors=5),                # doesn't have model.predict_proba so I left out.\n",
    "        \"GaussianNB\" : GaussianNB(),                                    #\n",
    "        \"LDA\" : LinearDiscriminantAnalysis(),                           # \n",
    "        \"Ridge\" : RidgeClassifier(),                                    #  \n",
    "        \"QDA\" : QuadraticDiscriminantAnalysis(),                        #\n",
    "        \"Bagging\" : BaggingClassifier(),                                #\n",
    "        \"MLP\" : MLPClassifier(),                                        #\n",
    "        \"LSVC\" : LinearSVC(),                                           #  \n",
    "        \"BernoulliNB\" : BernoulliNB(),                                  #  \n",
    "        \"Passive_AC\" : PassiveAggressiveClassifier(),                   # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #  \n",
    "        \"SGB\"     : GradientBoostingClassifier(n_estimators=100, random_state=9),\n",
    "        \"Adaboost\" : AdaBoostClassifier(n_estimators=100, random_state=9, algorithm='SAMME.R', learning_rate=0.8),\n",
    "        \"Extra_T\" : ExtraTreesClassifier(n_estimators=100, max_features=3),\n",
    "        \"R_forest\" : RandomForestClassifier(max_samples=0.9, n_estimators=100, max_features=3),\n",
    "        # \"XGB\" : xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)\n",
    "        }\n",
    "    return Models\n",
    " \n",
    "\n",
    "### Add lgb, catboost and Stacking and ANN\n",
    "\n",
    "\n",
    "### virtualize end result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '../../data/processed/undersampling_test.parquet'\n",
    "test_data_path  = '../../data/processed/undersampling_test.parquet'\n",
    "target = 'Class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../data/\")\n",
    "from data_function import get_feat_and_target\n",
    "def features_labels_split(train_data_path, test_data_path, target):\n",
    "    train_dataset = pd.read_parquet(train_data_path)\n",
    "    test_dataset = pd.read_parquet(test_data_path)\n",
    "    train_features,train_label = get_feat_and_target(train_dataset, target)\n",
    "    test_features,test_label = get_feat_and_target(test_dataset, target)\n",
    "    return train_features, train_label, test_features, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliiting X and y\n",
      "spliiting X and y\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_parquet(train_data_path)\n",
    "test_dataset = pd.read_parquet(test_data_path)\n",
    "train_features,train_label = get_feat_and_target(train_dataset, target)\n",
    "test_features,test_label = get_feat_and_target(test_dataset, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " Models = build_and_load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': LogisticRegression(),\n",
       " 'Support Vector Classifier': SVC(),\n",
       " 'Decision Tree': DecisionTreeClassifier(max_depth=6),\n",
       " 'KNearest': KNeighborsClassifier(),\n",
       " 'GaussianNB': GaussianNB(),\n",
       " 'LDA': LinearDiscriminantAnalysis(),\n",
       " 'Ridge': RidgeClassifier(),\n",
       " 'QDA': QuadraticDiscriminantAnalysis(),\n",
       " 'Bagging': BaggingClassifier(),\n",
       " 'MLP': MLPClassifier(),\n",
       " 'LSVC': LinearSVC(),\n",
       " 'BernoulliNB': BernoulliNB(),\n",
       " 'Passive_AC': PassiveAggressiveClassifier(),\n",
       " 'SGB': GradientBoostingClassifier(random_state=9),\n",
       " 'Adaboost': AdaBoostClassifier(learning_rate=0.8, n_estimators=100, random_state=9),\n",
       " 'Extra_T': ExtraTreesClassifier(max_features=3),\n",
       " 'R_forest': RandomForestClassifier(max_features=3, max_samples=0.9)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(classifier, test_features, test_labels, avg_method):\n",
    "    \n",
    "    # make prediction\n",
    "    predictions   = classifier.predict(test_features)\n",
    "    base_score   = classifier.score(test_features,test_labels)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions, average=avg_method)\n",
    "    recall = recall_score(test_labels, predictions, average=avg_method)\n",
    "    f1score = f1_score(test_labels, predictions, average=avg_method)\n",
    "    Matrix = confusion_matrix(test_labels, predictions)\n",
    "    matrix_scores = { \n",
    "        \"true negative\"  : Matrix[0][0],\n",
    "        \"false positive\" : Matrix[0][1],\n",
    "        \"false negative\" : Matrix[1][0],\n",
    "        \"true positive \" : Matrix[1][1]\n",
    "    }\n",
    "    target_names = ['0','1']\n",
    "    print(\"Classification report\")\n",
    "    print(\"---------------------\",\"\\n\")\n",
    "    print(classification_report(test_labels, predictions,target_names=target_names),\"\\n\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(\"---------------------\",\"\\n\")\n",
    "    print(f\"{confusion_matrix} \\n\")\n",
    "\n",
    "    print(\"Accuracy Measures\")\n",
    "    print(\"---------------------\",\"\\n\")\n",
    "    print(\"Base score: \", base_score)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1 Score: \", f1score)\n",
    "    \n",
    "    return base_score,accuracy,precision,recall,f1score,matrix_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 1\n",
    "for Model_Name, classifier in Models.items():   \n",
    "        print(f\"{i}. {Model_Name}\")\n",
    "        # fit the model\n",
    "        classifier.fit(train_features, train_label)\n",
    "        i = i+1\n",
    "        with mlflow.start_run():\n",
    "        # Calculate the metrics\n",
    "                base_score,accuracy,precision,recall,f1score,matrix_scores = eval_metrics(classifier, \n",
    "                                                                        test_features, \n",
    "                                                                        test_label, \n",
    "                                                                        'weighted')\n",
    "                \n",
    "                mlflow.log_param(\"Models\"            , Model_Name)\n",
    "                mlflow.log_params(matrix_scores)\n",
    "                mlflow.log_metric(\"base_score\"      , base_score)\n",
    "                mlflow.log_metric(\"accuary\"         , accuracy)\n",
    "                mlflow.log_metric(\"av_precision\"    , precision)\n",
    "                mlflow.log_metric(\"recall\"          , recall)\n",
    "                mlflow.log_metric(\"f1\"              , f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
